<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Bitcoin price prediction | YSMILES HOME</title><meta name=keywords content="TensorFlow,RNN,Bitcoin"><meta name=description content="1. Introduction This is a small project to learn basics of TensorFlow and solving time series problems with RNN. For more details, please refer to the codes at Github: ysmiles.
1.1 Time-series A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data."><meta name=author content="Frederick"><link rel=canonical href=/posts/bitcoin-price-prediction/><link crossorigin=anonymous href=/assets/css/stylesheet.ddbf7219471e1126282438a902837d962a32b41ca0eb0fdcbea41bcd83b8d308.css integrity="sha256-3b9yGUceESYoJDipAoN9lioytByg6w/cvqQbzYO40wg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=/images/yun-da.png><link rel=mask-icon href=/images/yun-da.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Bitcoin price prediction"><meta property="og:description" content="1. Introduction This is a small project to learn basics of TensorFlow and solving time series problems with RNN. For more details, please refer to the codes at Github: ysmiles.
1.1 Time-series A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data."><meta property="og:type" content="article"><meta property="og:url" content="/posts/bitcoin-price-prediction/"><meta property="og:image" content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-10-22T00:00:00+00:00"><meta property="article:modified_time" content="2017-10-22T00:00:00+00:00"><meta property="og:site_name" content="ysmiles homepage"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Bitcoin price prediction"><meta name=twitter:description content="1. Introduction This is a small project to learn basics of TensorFlow and solving time series problems with RNN. For more details, please refer to the codes at Github: ysmiles.
1.1 Time-series A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"/posts/"},{"@type":"ListItem","position":3,"name":"Bitcoin price prediction","item":"/posts/bitcoin-price-prediction/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Bitcoin price prediction","name":"Bitcoin price prediction","description":"1. Introduction This is a small project to learn basics of TensorFlow and solving time series problems with RNN. For more details, please refer to the codes at Github: ysmiles.\n1.1 Time-series A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data.","keywords":["TensorFlow","RNN","Bitcoin"],"articleBody":"1. Introduction This is a small project to learn basics of TensorFlow and solving time series problems with RNN. For more details, please refer to the codes at Github: ysmiles.\n1.1 Time-series A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data.\n1-D time series examples include weather information, stock exchange information, voice information (if we only consider strength or frequency).\nBitcoin price is similar to stocks but may changes more fast. For example, at the beginning of this month (2017-10-01) it was around $4400, and now (2017-10-20) it is almost $6000, with the increasing ratio of more than 36%. So accurate prediction of future prices of Bitcoin is very attractive.\n1.2 Recurrent Neural Networks (RNN) Recurrent Neural Networks (RNNs) are called recurrent because they perform the same computations for all elements in a sequence of inputs.\nRNNs are good at analyze time series data, such as stock prices, and provide forecasts. This is why this homework chose this method.\nRNNs can also take sentences, documents, or audio, etc as input, making them extremely useful for natural language processing (NLP) systems, such as automatic translation, speech-to-text, or sentiment analysis. Overall this method can be applied in many situations where a sequence of data points exists.\nThis image shows the RNN architecture.\nxt is the input at time step t. For example, in this project x1 could be the first price of Bitcoin in a specific time period. st is the hidden state at time step tn and is calculated based on the previous hidden state and the input at the current step, using an activation function. St-1 is usually initialized to zero. ot is the output at step t. For example, if we wanted to predict the next value in a sequence, it would be a vector of probabilities across our time series.\nRNN cells are developed on the notion that one input is dependent on the previous input by having a hidden state, or memory, that captures what has been seen so far. The value of the hidden state at any point in time is a function of the value of the hidden state at the previous time step and the value of the input at the current time step. In this project, I divide time serial data points as 20 days block. Actually what the whole program do is to finding feature and use 20 days price to predict price of 21st day.\n2. Implementation 2.1 Installation of Tensorflow Install Tensorflow at a linux server or desktop is not that hard. Here is a summary of installation bach commands from official guide.\n# for ubuntu $ sudo apt-get install python3-pip python3-dev python-virtualenv # for Python 3.n $ virtualenv --system-site-packages -p python3 ~/tensorflow # for Python 3.n $ source ~/tensorflow/bin/activate # bash, sh, ksh, or zsh # Assume at least have python 3.5 (tensorflow)$ pip3 install --upgrade tensorflow # for Python 3.n One note here is to use virtualenv, which provide a separated python environment to tensorflow. The goodness of this is that inside this environment, we do not need to care python or python3, pip or pip3, etc. In my case, it only has python 3 inside. Because linux servers always have some python 2 version(s), which is quite annoying for stricting version every time. So this virtualenv does help. Just remember to activate it as showed above.\nI also test this project at Windows 10. At the beginning I installed it in Anaconda, but it turned out to be with some problems. So I uninstalled Anaconda and installed official python 3.6 and used native installation with pip. It worked well.\nAt Windows system, here is another note. For some packages, the pip installation requires outside library that generally windows does not have. To solve this, one could go to following page to download compiled version of packages and then use local pip install.\nhttp://www.lfd.uci.edu/~gohlke/pythonlibs/\n2.2 Data preparation 2.2.1 Fetching data To meet the requirement “load data from remote”, there are two basic choices. One is build a database, insert data, and using some api (say MySQL connector) to fetching data. The other one is to use some opened/paid and well-defined api to get structured or semi-structured data.\nThe first one is more practical, but the data source cannot be validated. I can randomly generate some data and insert it into database, then fetching it to local. But in this way, it is kind of similar as directly generate data locally.\nI chose the latter one, i.e. using an api already exists.\nAt the beginning, actually I planned to use some weather api doing temperature forecasting. But the free apis always only provide current data. The history data is somehow difficult to get.\nLuckily, for my planB (this one with Bitcoin), some websites provide good apis with history data. For example, conindesk.\nPython official suggests an api of fetching Bitcoin data. This package is shown in “exchanges” folder. It is written for python 2. I have modified some files to make it compatible with python 3.\nThe mainly used api function (modified) is as follow:\ndef get_historical_data_as_dict(cls, start='2017-01-01', end=None): if not end: end = get_datetime() data = cls._get_historical_data(start, end) prices = data['bpi'] # prices = {k: Decimal(str(v)) for (k,v) in prices.items()} prices = OrderedDict(sorted(prices.items(), key=lambda t: t[0])) return prices OrderedDict is used for make the dictionary sorted. Because I noticed that the return value from original message is not shown as the time order. For more details, please refer to coindesk.py in folder “exchanges”.\nFor easy calling, I wrapped it in getBCdata in datafetch.py.\ndef getBCdata(start='2017-01-01', end=None): return CoinDesk.get_historical_data_as_dict(start, end) 2.2.2 Preparation Preparation can further divide to two small part.\nstartdate = '2017-01-01' enddate = '2017-10-20' rng = pd.date_range(start=startdate, end=enddate, freq='D') ts = getBCdata(startdate, enddate) # ts = pd.Series([v for (k, v) in ts.items()]) TS = np.array([v for (k, v) in ts.items()]) This part calls predefined api and get data.\nnum_periods = 20 f_horizon = 1 # forecast horizon, one period into the future x_data = TS[:(len(TS) - (len(TS) % num_periods))] x_batches = x_data.reshape(-1, 20, 1) y_data = TS[1:(len(TS) - (len(TS) % num_periods)) + f_horizon] y_batches = y_data.reshape(-1, 20, 1) # print(len(x_batches)) print('x batches shape', x_batches.shape) # print(x_batches[0:2]) # print(y_batches[0:1]) print('y batches shape', y_batches.shape) def test_data(series, forecast, num_periods): test_x_setup = TS[-(num_periods + forecast):] testX = test_x_setup[:num_periods].reshape(-1, 20, 1) testY = TS[-(num_periods):].reshape(-1, 20, 1) return testX, testY X_test, Y_test = test_data(TS, f_horizon, num_periods) print('Test shape', X_test.shape) # print(X_test) This part parses the data to 20-day blocks and prepare to do training. Also in this part it chose last 20 days data for testing. (If the total days mod 20 is not 0, at least some days were not taken as training data, and actually it just predicted one day more).\n2.3 Data processing This part is roughly similar to the RNN example from MapR.\nBasically, it did some fundamental setting of Tensorflow session and data.\nTraining activation function was chosen as “relu”. The mean square error was chosen as the loss function. The basic AdamOptimizer was used for minimizing loss function result.\nFor more details please refer the code and comments.\n# didn't have any previous graph objects running, but this would reset the graphs tf.reset_default_graph() # setted before # num_periods = 20 #number of periods per vector we are using to predict one period ahead inputs = 1 # number of vectors submitted hidden = 500 # number of neurons we will recursively work through, can be changed to improve accuracy output = 1 # number of output vectors # create variable objects X = tf.placeholder(tf.float32, [None, num_periods, inputs]) y = tf.placeholder(tf.float32, [None, num_periods, output]) basic_cell = tf.contrib.rnn.BasicRNNCell( num_units=hidden, activation=tf.nn.relu) # create our RNN object rnn_output, states = tf.nn.dynamic_rnn( basic_cell, X, dtype=tf.float32) # choose dynamic over static learning_rate = 0.001 # small learning rate so we don't overshoot the minimum # change the form into a tensor stacked_rnn_output = tf.reshape(rnn_output, [-1, hidden]) # specify the type of layer (dense) stacked_outputs = tf.layers.dense(stacked_rnn_output, output) # shape of results outputs = tf.reshape(stacked_outputs, [-1, num_periods, output]) # define the cost function which evaluates the quality of our model loss = tf.reduce_sum(tf.square(outputs - y)) optimizer = tf.train.AdamOptimizer( learning_rate=learning_rate) # gradient descent method # train the result of the application of the cost_function training_op = optimizer.minimize(loss) init = tf.global_variables_initializer() # initialize all the variables epochs = 2000 # number of iterations or training cycles, includes both the FeedFoward and Backpropogation with tf.Session() as sess: init.run() for ep in range(epochs): sess.run(training_op, feed_dict={X: x_batches, y: y_batches}) The testing of (with last 20 days results) is quite easy. To get predicted data:\ny_pred = sess.run(outputs, feed_dict={X: X_test}) 3. Visualization 3.1 Windows/Linux The main output of Windows/Linux platform. Here we have four images, the test result of last period of days, loss function (mean square error) result, CPU usage, and memory usage.\nFor discussion of results please refer to part 4 of this article.\nHere are some screenshots.\n3.2 Web interface The web interface is implemented with Tensorboard from Tensorflow.\nThe first screenshot shows the training process, while other images are pretty similar to general PC platform.\nFor detailed implementation, please refer the code.\n4. Discussion and Summary Result discussion\nWe can see the prediction of last 20 prices of recently day looks similar to true value on trend. Overall the loss decrease fast at the beginning but the decreasing rate speed down later at more running cycles. For each data point, it is still not that accurate. MSE also can support this for still keeping at relatively large value. It should not be enough to get profits by this easy model. More optimizations need to be done, not only to increase looping times or the hidden middle layers. CPU usage is normal for training process. I am using an Intel i7-6700K CPU (4 core, 8 hyperthreads) with 16G DDR4 RAM. Memory usage also looks good, running more cycles did not cost much more memory. By going through all of those steps, I learned the basics of machine learning steps as well as got to know the working logic of Tensorflow.\nThe final visualization adjusting/debugging and documenting costed more time than I expected. Next time I need to leave more time for those steps.\nReference https://en.wikipedia.org/wiki/Time_series\nhttps://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8\nhttps://mapr.com/blog/deep-learning-tensorflow/\nhttps://github.com/dursk/bitcoin-price-api\n","wordCount":"1733","inLanguage":"en","datePublished":"2017-10-22T00:00:00Z","dateModified":"2017-10-22T00:00:00Z","author":{"@type":"Person","name":"Frederick"},"mainEntityOfPage":{"@type":"WebPage","@id":"/posts/bitcoin-price-prediction/"},"publisher":{"@type":"Organization","name":"YSMILES HOME","logo":{"@type":"ImageObject","url":"/images/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="ysmiles (Alt + H)"><img src=/images/yun-da.png alt aria-label=logo height=35>ysmiles</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=/about title="About me"><span>About me</span></a></li><li><a href=/tags title=Tags><span>Tags</span></a></li><li><a href=/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/posts/>Posts</a></div><h1 class=post-title>Bitcoin price prediction</h1><div class=post-meta><span title='2017-10-22 00:00:00 +0000 UTC'>October 22, 2017</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Frederick</div></header><div class=post-content><h2 id=1-introduction>1. Introduction<a hidden class=anchor aria-hidden=true href=#1-introduction>#</a></h2><p>This is a small project to learn basics of TensorFlow and solving time series problems with RNN.
For more details, please refer to the codes at <a href=https://github.com/ysmiles/tensorflow-learn/tree/master/bitcoinPricePredict>Github: ysmiles</a>.</p><h3 id=11-time-series>1.1 Time-series<a hidden class=anchor aria-hidden=true href=#11-time-series>#</a></h3><p>A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data.</p><p>1-D time series examples include weather information, stock exchange information, voice information (if we only consider strength or frequency).</p><p>Bitcoin price is similar to stocks but may changes more fast.
For example, at the beginning of this month (2017-10-01) it was around <strong>$4400</strong>, and now (2017-10-20) it is almost <strong>$6000</strong>, with the increasing ratio of more than <strong>36%</strong>.
So accurate prediction of future prices of Bitcoin is very attractive.</p><h3 id=12-recurrent-neural-networks-rnn>1.2 Recurrent Neural Networks (RNN)<a hidden class=anchor aria-hidden=true href=#12-recurrent-neural-networks-rnn>#</a></h3><p>Recurrent Neural Networks (RNNs) are called recurrent because they perform the same computations for all elements in a sequence of inputs.</p><p>RNNs are good at analyze time series data, such as stock prices, and provide forecasts.
This is why this homework chose this method.</p><p>RNNs can also take sentences, documents, or audio, etc as input, making them extremely useful for natural language processing (NLP) systems, such as automatic translation, speech-to-text, or sentiment analysis.
Overall this method can be applied in many situations where a sequence of data points exists.</p><p><img loading=lazy src=/images/bitcoinprice/rnn.png alt=rnn></p><p>This image shows the RNN architecture.</p><p><code>xt</code> is the input at time step <code>t</code>. For example, in this project <code>x1</code> could be the first price of Bitcoin in a specific time period.
<code>st</code> is the hidden state at time step <code>tn</code> and is calculated based on the previous hidden state and the input at the current step, using an activation function.
<code>St-1</code> is usually initialized to zero.
<code>ot</code> is the output at step <code>t</code>.
For example, if we wanted to predict the next value in a sequence, it would be a vector of probabilities across our time series.</p><p>RNN cells are developed on the notion that one input is dependent on the previous input by having a hidden state, or memory, that captures what has been seen so far.
The value of the hidden state at any point in time is a function of the value of the hidden state at the previous time step and the value of the input at the current time step.
In this project, I divide time serial data points as 20 days block. Actually what the whole program do is to finding feature and use 20 days price to predict price of 21st day.</p><h2 id=2-implementation>2. Implementation<a hidden class=anchor aria-hidden=true href=#2-implementation>#</a></h2><h3 id=21-installation-of-tensorflow>2.1 Installation of Tensorflow<a hidden class=anchor aria-hidden=true href=#21-installation-of-tensorflow>#</a></h3><p>Install Tensorflow at a linux server or desktop is not that hard. Here is a summary of installation bach commands from official guide.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># for ubuntu</span>
</span></span><span style=display:flex><span>$ sudo apt-get install python3-pip python3-dev python-virtualenv <span style=color:#75715e># for Python 3.n</span>
</span></span><span style=display:flex><span>$ virtualenv --system-site-packages -p python3 ~/tensorflow <span style=color:#75715e># for Python 3.n</span>
</span></span><span style=display:flex><span>$ source ~/tensorflow/bin/activate <span style=color:#75715e># bash, sh, ksh, or zsh</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Assume at least have python 3.5</span>
</span></span><span style=display:flex><span><span style=color:#f92672>(</span>tensorflow<span style=color:#f92672>)</span>$ pip3 install --upgrade tensorflow     <span style=color:#75715e># for Python 3.n</span>
</span></span></code></pre></div><p>One note here is to use <code>virtualenv</code>, which provide a separated python environment to tensorflow.
The goodness of this is that inside this environment, we do not need to care python or python3, pip or pip3, etc.
In my case, it only has python 3 inside.
Because linux servers always have some python 2 version(s), which is quite annoying for stricting version every time.
So this <code>virtualenv</code> does help.
Just remember to <code>activate</code> it as showed above.</p><p>I also test this project at Windows 10.
At the beginning I installed it in Anaconda, but it turned out to be with some problems.
So I uninstalled Anaconda and installed official python 3.6 and used native installation with pip.
It worked well.</p><p>At Windows system, here is another note.
For some packages, the pip installation requires outside library that generally windows does not have.
To solve this, one could go to following page to download compiled version of packages and then use local pip install.</p><p><a href=http://www.lfd.uci.edu/~gohlke/pythonlibs/>http://www.lfd.uci.edu/~gohlke/pythonlibs/</a></p><h3 id=22-data-preparation>2.2 Data preparation<a hidden class=anchor aria-hidden=true href=#22-data-preparation>#</a></h3><h4 id=221-fetching-data>2.2.1 Fetching data<a hidden class=anchor aria-hidden=true href=#221-fetching-data>#</a></h4><p>To meet the requirement &ldquo;load data from remote&rdquo;, there are two basic choices.
One is build a database, insert data, and using some api (say MySQL connector) to fetching data.
The other one is to use some opened/paid and well-defined api to get structured or semi-structured data.</p><p>The first one is more practical, but the data source cannot be validated.
I can randomly generate some data and insert it into database, then fetching it to local.
But in this way, it is kind of similar as directly generate data locally.</p><p>I chose the latter one, i.e. using an api already exists.</p><p>At the beginning, actually I planned to use some weather api doing temperature forecasting.
But the free apis always only provide current data.
The history data is somehow difficult to get.</p><p>Luckily, for my planB (this one with Bitcoin), some websites provide good apis with history data. For example, <a href=https://coindesk.com>conindesk</a>.</p><p>Python official suggests an api of fetching Bitcoin data.
This package is shown in &ldquo;exchanges&rdquo; folder.
It is written for python 2.
I have modified some files to make it compatible with python 3.</p><p>The mainly used api function (modified) is as follow:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_historical_data_as_dict</span>(cls, start<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;2017-01-01&#39;</span>, end<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> end:
</span></span><span style=display:flex><span>        end <span style=color:#f92672>=</span> get_datetime()
</span></span><span style=display:flex><span>    data <span style=color:#f92672>=</span> cls<span style=color:#f92672>.</span>_get_historical_data(start, end)
</span></span><span style=display:flex><span>    prices <span style=color:#f92672>=</span> data[<span style=color:#e6db74>&#39;bpi&#39;</span>]
</span></span><span style=display:flex><span>    <span style=color:#75715e># prices = {k: Decimal(str(v)) for (k,v) in prices.items()}</span>
</span></span><span style=display:flex><span>    prices <span style=color:#f92672>=</span> OrderedDict(sorted(prices<span style=color:#f92672>.</span>items(), key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> t: t[<span style=color:#ae81ff>0</span>]))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> prices
</span></span></code></pre></div><p><code>OrderedDict</code> is used for make the dictionary sorted.
Because I noticed that the return value from original message is not shown as the time order.
For more details, please refer to <code>coindesk.py</code> in folder &ldquo;exchanges&rdquo;.</p><p>For easy calling, I wrapped it in <code>getBCdata</code> in <code>datafetch.py</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getBCdata</span>(start<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;2017-01-01&#39;</span>, end<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> CoinDesk<span style=color:#f92672>.</span>get_historical_data_as_dict(start, end)
</span></span></code></pre></div><h4 id=222-preparation>2.2.2 Preparation<a hidden class=anchor aria-hidden=true href=#222-preparation>#</a></h4><p>Preparation can further divide to two small part.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>startdate <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;2017-01-01&#39;</span>
</span></span><span style=display:flex><span>enddate <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;2017-10-20&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rng <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>date_range(start<span style=color:#f92672>=</span>startdate, end<span style=color:#f92672>=</span>enddate, freq<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;D&#39;</span>)
</span></span><span style=display:flex><span>ts <span style=color:#f92672>=</span> getBCdata(startdate, enddate)
</span></span><span style=display:flex><span><span style=color:#75715e># ts = pd.Series([v for (k, v) in ts.items()])</span>
</span></span><span style=display:flex><span>TS <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([v <span style=color:#66d9ef>for</span> (k, v) <span style=color:#f92672>in</span> ts<span style=color:#f92672>.</span>items()])
</span></span></code></pre></div><p>This part calls predefined api and get data.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>num_periods <span style=color:#f92672>=</span> <span style=color:#ae81ff>20</span>
</span></span><span style=display:flex><span>f_horizon <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># forecast horizon, one period into the future</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x_data <span style=color:#f92672>=</span> TS[:(len(TS) <span style=color:#f92672>-</span> (len(TS) <span style=color:#f92672>%</span> num_periods))]
</span></span><span style=display:flex><span>x_batches <span style=color:#f92672>=</span> x_data<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_data <span style=color:#f92672>=</span> TS[<span style=color:#ae81ff>1</span>:(len(TS) <span style=color:#f92672>-</span> (len(TS) <span style=color:#f92672>%</span> num_periods)) <span style=color:#f92672>+</span> f_horizon]
</span></span><span style=display:flex><span>y_batches <span style=color:#f92672>=</span> y_data<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># print(len(x_batches))</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;x batches shape&#39;</span>, x_batches<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span><span style=color:#75715e># print(x_batches[0:2])</span>
</span></span><span style=display:flex><span><span style=color:#75715e># print(y_batches[0:1])</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;y batches shape&#39;</span>, y_batches<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_data</span>(series, forecast, num_periods):
</span></span><span style=display:flex><span>    test_x_setup <span style=color:#f92672>=</span> TS[<span style=color:#f92672>-</span>(num_periods <span style=color:#f92672>+</span> forecast):]
</span></span><span style=display:flex><span>    testX <span style=color:#f92672>=</span> test_x_setup[:num_periods]<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    testY <span style=color:#f92672>=</span> TS[<span style=color:#f92672>-</span>(num_periods):]<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> testX, testY
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X_test, Y_test <span style=color:#f92672>=</span> test_data(TS, f_horizon, num_periods)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;Test shape&#39;</span>, X_test<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span><span style=color:#75715e># print(X_test)</span>
</span></span></code></pre></div><p>This part parses the data to 20-day blocks and prepare to do training.
Also in this part it chose last 20 days data for testing.
(If the total days mod 20 is not 0, at least some days were not taken as training data, and actually it just predicted one day more).</p><h3 id=23-data-processing>2.3 Data processing<a hidden class=anchor aria-hidden=true href=#23-data-processing>#</a></h3><p>This part is roughly similar to the RNN example from MapR.</p><p>Basically, it did some fundamental setting of Tensorflow session and data.</p><p>Training activation function was chosen as &ldquo;relu&rdquo;.
The mean square error was chosen as the loss function.
The basic AdamOptimizer was used for minimizing loss function result.</p><p>For more details please refer the code and comments.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># didn&#39;t have any previous graph objects running, but this would reset the graphs</span>
</span></span><span style=display:flex><span>tf<span style=color:#f92672>.</span>reset_default_graph()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># setted before</span>
</span></span><span style=display:flex><span><span style=color:#75715e># num_periods = 20      #number of periods per vector we are using to predict one period ahead</span>
</span></span><span style=display:flex><span>inputs <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># number of vectors submitted</span>
</span></span><span style=display:flex><span>hidden <span style=color:#f92672>=</span> <span style=color:#ae81ff>500</span>  <span style=color:#75715e># number of neurons we will recursively work through, can be changed to improve accuracy</span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># number of output vectors</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create variable objects</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>placeholder(tf<span style=color:#f92672>.</span>float32, [<span style=color:#66d9ef>None</span>, num_periods, inputs])
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>placeholder(tf<span style=color:#f92672>.</span>float32, [<span style=color:#66d9ef>None</span>, num_periods, output])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>basic_cell <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>contrib<span style=color:#f92672>.</span>rnn<span style=color:#f92672>.</span>BasicRNNCell(
</span></span><span style=display:flex><span>    num_units<span style=color:#f92672>=</span>hidden, activation<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>relu)  <span style=color:#75715e># create our RNN object</span>
</span></span><span style=display:flex><span>rnn_output, states <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>dynamic_rnn(
</span></span><span style=display:flex><span>    basic_cell, X, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>float32)  <span style=color:#75715e># choose dynamic over static</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>learning_rate <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.001</span>  <span style=color:#75715e># small learning rate so we don&#39;t overshoot the minimum</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># change the form into a tensor</span>
</span></span><span style=display:flex><span>stacked_rnn_output <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(rnn_output, [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, hidden])
</span></span><span style=display:flex><span><span style=color:#75715e># specify the type of layer (dense)</span>
</span></span><span style=display:flex><span>stacked_outputs <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>dense(stacked_rnn_output, output)
</span></span><span style=display:flex><span><span style=color:#75715e># shape of results</span>
</span></span><span style=display:flex><span>outputs <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(stacked_outputs, [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, num_periods, output])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># define the cost function which evaluates the quality of our model</span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reduce_sum(tf<span style=color:#f92672>.</span>square(outputs <span style=color:#f92672>-</span> y))
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>train<span style=color:#f92672>.</span>AdamOptimizer(
</span></span><span style=display:flex><span>    learning_rate<span style=color:#f92672>=</span>learning_rate)  <span style=color:#75715e># gradient descent method</span>
</span></span><span style=display:flex><span><span style=color:#75715e># train the result of the application of the cost_function</span>
</span></span><span style=display:flex><span>training_op <span style=color:#f92672>=</span> optimizer<span style=color:#f92672>.</span>minimize(loss)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>init <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>global_variables_initializer()  <span style=color:#75715e># initialize all the variables</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>2000</span>  <span style=color:#75715e># number of iterations or training cycles, includes both the FeedFoward and Backpropogation</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> tf<span style=color:#f92672>.</span>Session() <span style=color:#66d9ef>as</span> sess:
</span></span><span style=display:flex><span>    init<span style=color:#f92672>.</span>run()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> ep <span style=color:#f92672>in</span> range(epochs):
</span></span><span style=display:flex><span>        sess<span style=color:#f92672>.</span>run(training_op, feed_dict<span style=color:#f92672>=</span>{X: x_batches, y: y_batches})
</span></span></code></pre></div><p>The testing of (with last 20 days results) is quite easy.
To get predicted data:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>    y_pred <span style=color:#f92672>=</span> sess<span style=color:#f92672>.</span>run(outputs, feed_dict<span style=color:#f92672>=</span>{X: X_test})
</span></span></code></pre></div><h2 id=3-visualization>3. Visualization<a hidden class=anchor aria-hidden=true href=#3-visualization>#</a></h2><h3 id=31-windowslinux>3.1 Windows/Linux<a hidden class=anchor aria-hidden=true href=#31-windowslinux>#</a></h3><p>The main output of Windows/Linux platform.
Here we have four images, the test result of last period of days, loss function (mean square error) result, CPU usage, and memory usage.</p><p>For discussion of results please refer to part 4 of this article.</p><p>Here are some screenshots.</p><p><img loading=lazy src=/images/bitcoinprice/all.png alt=all></p><p><img loading=lazy src=/images/bitcoinprice/result.svg alt=result>
<img loading=lazy src=/images/bitcoinprice/loss.svg alt=loss>
<img loading=lazy src=/images/bitcoinprice/cpu.svg alt=cpu>
<img loading=lazy src=/images/bitcoinprice/mem.svg alt=mem></p><h3 id=32-web-interface>3.2 Web interface<a hidden class=anchor aria-hidden=true href=#32-web-interface>#</a></h3><p>The web interface is implemented with Tensorboard from Tensorflow.</p><p>The first screenshot shows the training process, while other images are pretty similar to general PC platform.</p><p>For detailed implementation, please refer the code.</p><p><img loading=lazy src=/images/bitcoinprice/training.png alt=training>
<img loading=lazy src=/images/bitcoinprice/allw.png alt=allw>
<img loading=lazy src=/images/bitcoinprice/lossw.png alt=lossw>
<img loading=lazy src=/images/bitcoinprice/cpuw.png alt=cpuw>
<img loading=lazy src=/images/bitcoinprice/memw.png alt=memw></p><h2 id=4-discussion-and-summary>4. Discussion and Summary<a hidden class=anchor aria-hidden=true href=#4-discussion-and-summary>#</a></h2><ul><li><p>Result discussion</p><ul><li>We can see the prediction of last 20 prices of recently day looks similar to true value on trend.</li><li>Overall the loss decrease fast at the beginning but the decreasing rate speed down later at more running cycles.</li><li>For each data point, it is still not that accurate. MSE also can support this for still keeping at relatively large value.</li><li>It should not be enough to get profits by this easy model. More optimizations need to be done, not only to increase looping times or the hidden middle layers.</li><li>CPU usage is normal for training process. I am using an Intel i7-6700K CPU (4 core, 8 hyperthreads) with 16G DDR4 RAM.</li><li>Memory usage also looks good, running more cycles did not cost much more memory.</li></ul></li><li><p>By going through all of those steps, I learned the basics of machine learning steps as well as got to know the working logic of Tensorflow.</p></li><li><p>The final visualization adjusting/debugging and documenting costed more time than I expected.
Next time I need to leave more time for those steps.</p></li></ul><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><p><a href=https://en.wikipedia.org/wiki/Time_series>https://en.wikipedia.org/wiki/Time_series</a></p><p><a href=https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8>https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8</a></p><p><a href=https://mapr.com/blog/deep-learning-tensorflow/>https://mapr.com/blog/deep-learning-tensorflow/</a></p><p><a href=https://github.com/dursk/bitcoin-price-api>https://github.com/dursk/bitcoin-price-api</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=/tags/tensorflow/>TensorFlow</a></li><li><a href=/tags/rnn/>RNN</a></li><li><a href=/tags/bitcoin/>Bitcoin</a></li></ul><nav class=paginav><a class=prev href=/posts/http-server-inside-a-docker-container/><span class=title>« Prev</span><br><span>HTTP server inside a docker container</span></a>
<a class=next href=/posts/run-a-basic-grpc-example-with-docker/><span class=title>Next »</span><br><span>Run a basic gRPC example with Docker</span></a></nav></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//ysmiles.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a><nav id=TableOfContents><h2></h2><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a><ul><li><a href=#11-time-series>1.1 Time-series</a></li><li><a href=#12-recurrent-neural-networks-rnn>1.2 Recurrent Neural Networks (RNN)</a></li></ul></li><li><a href=#2-implementation>2. Implementation</a><ul><li><a href=#21-installation-of-tensorflow>2.1 Installation of Tensorflow</a></li><li><a href=#22-data-preparation>2.2 Data preparation</a></li><li><a href=#23-data-processing>2.3 Data processing</a></li></ul></li><li><a href=#3-visualization>3. Visualization</a><ul><li><a href=#31-windowslinux>3.1 Windows/Linux</a></li><li><a href=#32-web-interface>3.2 Web interface</a></li></ul></li><li><a href=#4-discussion-and-summary>4. Discussion and Summary</a></li><li><a href=#reference>Reference</a></li></ul></nav></nav></article></main><footer class=footer><span>&copy; 2023 <a href>YSMILES HOME</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>